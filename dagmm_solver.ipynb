{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "from torch.autograd import grad\n",
    "from torch.autograd import Variable\n",
    "from local.dagmm.model import *\n",
    "import matplotlib.pyplot as plt\n",
    "from local.dagmm.utils import *\n",
    "from local.dagmm.data_loader import *\n",
    "import IPython\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from local.imports import *\n",
    "from local.notebook.export import *\n",
    "from torch.backends import cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp dagmm.solver\n",
    "# default_cls_lvl 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Solver(object):\n",
    "    DEFAULTS = {}   \n",
    "    def __init__(self, data_loader, config):\n",
    "        # Data loader\n",
    "        self.__dict__.update(Solver.DEFAULTS, **config)\n",
    "        self.data_loader = data_loader\n",
    "\n",
    "        # Build tensorboard if use\n",
    "        self.build_model()\n",
    "        if self.use_tensorboard:\n",
    "            self.build_tensorboard()\n",
    "\n",
    "        # Start with trained model\n",
    "        if self.pretrained_model:\n",
    "            self.load_pretrained_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        # Define model\n",
    "        self.dagmm = DaGMM(self.gmm_k)\n",
    "\n",
    "        # Optimizers\n",
    "        self.optimizer = torch.optim.Adam(self.dagmm.parameters(), lr=self.lr)\n",
    "\n",
    "        # Print networks\n",
    "        self.print_network(self.dagmm, 'DaGMM')\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            self.dagmm.cuda()\n",
    "\n",
    "    def print_network(self, model, name):\n",
    "        num_params = 0\n",
    "        for p in model.parameters():\n",
    "            num_params += p.numel()\n",
    "        print(name)\n",
    "        print(model)\n",
    "        print(\"The number of parameters: {}\".format(num_params))\n",
    "\n",
    "    def load_pretrained_model(self):\n",
    "        self.dagmm.load_state_dict(torch.load(os.path.join(\n",
    "            self.model_save_path, '{}_dagmm.pth'.format(self.pretrained_model))))\n",
    "\n",
    "        print(\"phi\", self.dagmm.phi,\"mu\",self.dagmm.mu, \"cov\",self.dagmm.cov)\n",
    "\n",
    "        print('loaded trained models (step: {})..!'.format(self.pretrained_model))\n",
    "\n",
    "    def build_tensorboard(self):\n",
    "        from logger import Logger\n",
    "        self.logger = Logger(self.log_path)\n",
    "\n",
    "    def reset_grad(self):\n",
    "        self.dagmm.zero_grad()\n",
    "\n",
    "    def to_var(self, x, volatile=False):\n",
    "        if torch.cuda.is_available():\n",
    "            x = x.cuda()\n",
    "        return Variable(x, volatile=volatile)\n",
    "\n",
    "    def train(self):\n",
    "        iters_per_epoch = len(self.data_loader)\n",
    "\n",
    "        # Start with trained model if exists\n",
    "        if self.pretrained_model:\n",
    "            start = int(self.pretrained_model.split('_')[0])\n",
    "        else:\n",
    "            start = 0\n",
    "\n",
    "        # Start training\n",
    "        iter_ctr = 0\n",
    "        start_time = time.time()\n",
    "\n",
    "        self.ap_global_train = np.array([0,0,0])\n",
    "        for e in range(start, self.num_epochs):\n",
    "            for i, (input_data, labels) in enumerate(tqdm(self.data_loader)):\n",
    "                iter_ctr += 1\n",
    "                start = time.time()\n",
    "\n",
    "                input_data = self.to_var(input_data)\n",
    "\n",
    "                total_loss,sample_energy, recon_error, cov_diag = self.dagmm_step(input_data)\n",
    "                # Logging\n",
    "                loss = {}\n",
    "                loss['total_loss'] = total_loss.data.item()\n",
    "                loss['sample_energy'] = sample_energy.item()\n",
    "                loss['recon_error'] = recon_error.item()\n",
    "                loss['cov_diag'] = cov_diag.item()\n",
    "\n",
    "\n",
    "\n",
    "                # Print out log info\n",
    "                if (i+1) % self.log_step == 0:\n",
    "                    elapsed = time.time() - start_time\n",
    "                    total_time = ((self.num_epochs*iters_per_epoch)-(e*iters_per_epoch+i)) * elapsed/(e*iters_per_epoch+i+1)\n",
    "                    epoch_time = (iters_per_epoch-i)* elapsed/(e*iters_per_epoch+i+1)\n",
    "                    \n",
    "                    epoch_time = str(datetime.timedelta(seconds=epoch_time))\n",
    "                    total_time = str(datetime.timedelta(seconds=total_time))\n",
    "                    elapsed = str(datetime.timedelta(seconds=elapsed))\n",
    "\n",
    "                    lr_tmp = []\n",
    "                    for param_group in self.optimizer.param_groups:\n",
    "                        lr_tmp.append(param_group['lr'])\n",
    "                    tmplr = np.squeeze(np.array(lr_tmp))\n",
    "\n",
    "                    log = \"Elapsed {}/{} -- {} , Epoch [{}/{}], Iter [{}/{}], lr {}\".format(\n",
    "                        elapsed,epoch_time,total_time, e+1, self.num_epochs, i+1, iters_per_epoch, tmplr)\n",
    "\n",
    "                    for tag, value in loss.items():\n",
    "                        log += \", {}: {:.4f}\".format(tag, value)\n",
    "\n",
    "                    IPython.display.clear_output()\n",
    "                    print(log)\n",
    "\n",
    "                    if self.use_tensorboard:\n",
    "                        for tag, value in loss.items():\n",
    "                            self.logger.scalar_summary(tag, value, e * iters_per_epoch + i + 1)\n",
    "                    else:\n",
    "                        plt_ctr = 1\n",
    "                        if not hasattr(self,\"loss_logs\"):\n",
    "                            self.loss_logs = {}\n",
    "                            for loss_key in loss:\n",
    "                                self.loss_logs[loss_key] = [loss[loss_key]]\n",
    "                                plt.subplot(2,2,plt_ctr)\n",
    "                                plt.plot(np.array(self.loss_logs[loss_key]), label=loss_key)\n",
    "                                plt.legend()\n",
    "                                plt_ctr += 1\n",
    "                        else:\n",
    "                            for loss_key in loss:\n",
    "                                self.loss_logs[loss_key].append(loss[loss_key])\n",
    "                                plt.subplot(2,2,plt_ctr)\n",
    "                                plt.plot(np.array(self.loss_logs[loss_key]), label=loss_key)\n",
    "                                plt.legend()\n",
    "                                plt_ctr += 1\n",
    "\n",
    "                        plt.show()\n",
    "\n",
    "                    print(\"phi\", self.dagmm.phi,\"mu\",self.dagmm.mu, \"cov\",self.dagmm.cov)\n",
    "                # Save model checkpoints\n",
    "                if (i+1) % self.model_save_step == 0:\n",
    "                    torch.save(self.dagmm.state_dict(),\n",
    "                        os.path.join(self.model_save_path, '{}_{}_dagmm.pth'.format(e+1, i+1)))\n",
    "\n",
    "    def dagmm_step(self, input_data):\n",
    "        self.dagmm.train()\n",
    "        enc, dec, z, gamma = self.dagmm(input_data)\n",
    "\n",
    "        total_loss, sample_energy, recon_error, cov_diag = self.dagmm.loss_function(input_data, dec, z, gamma, self.lambda_energy, self.lambda_cov_diag)\n",
    "\n",
    "        self.reset_grad()\n",
    "        total_loss = Variable(total_loss, requires_grad =True)\n",
    "        total_loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(self.dagmm.parameters(), 5)\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return total_loss,sample_energy, recon_error, cov_diag\n",
    "\n",
    "    def test(self):\n",
    "        print(\"======================TEST MODE======================\")\n",
    "        self.dagmm.eval()\n",
    "        self.data_loader.dataset.mode=\"train\"\n",
    "\n",
    "        N = 0\n",
    "        mu_sum = 0\n",
    "        cov_sum = 0\n",
    "        gamma_sum = 0\n",
    "\n",
    "        for it, (input_data, labels) in enumerate(self.data_loader):\n",
    "            input_data = self.to_var(input_data)\n",
    "            enc, dec, z, gamma = self.dagmm(input_data)\n",
    "            phi, mu, cov = self.dagmm.compute_gmm_params(z, gamma)\n",
    "            \n",
    "            batch_gamma_sum = torch.sum(gamma, dim=0)\n",
    "            \n",
    "            gamma_sum += batch_gamma_sum\n",
    "            mu_sum += mu * batch_gamma_sum.unsqueeze(-1) # keep sums of the numerator only\n",
    "            cov_sum += cov * batch_gamma_sum.unsqueeze(-1).unsqueeze(-1) # keep sums of the numerator only\n",
    "            \n",
    "            N += input_data.size(0)\n",
    "            \n",
    "        train_phi = gamma_sum / N\n",
    "        train_mu = mu_sum / gamma_sum.unsqueeze(-1)\n",
    "        train_cov = cov_sum / gamma_sum.unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        print(\"N:\",N)\n",
    "        print(\"phi :\\n\",train_phi)\n",
    "        print(\"mu :\\n\",train_mu)\n",
    "        print(\"cov :\\n\",train_cov)\n",
    "\n",
    "        train_energy = []\n",
    "        train_labels = []\n",
    "        train_z = []\n",
    "        for it, (input_data, labels) in enumerate(self.data_loader):\n",
    "            input_data = self.to_var(input_data)\n",
    "            enc, dec, z, gamma = self.dagmm(input_data)\n",
    "            sample_energy, cov_diag = self.dagmm.compute_energy(z, phi=train_phi, mu=train_mu, cov=train_cov, size_average=False)\n",
    "            \n",
    "            train_energy.append(sample_energy.data.cpu().numpy())\n",
    "            train_z.append(z.data.cpu().numpy())\n",
    "            train_labels.append(labels.numpy())\n",
    "\n",
    "\n",
    "        train_energy = np.concatenate(train_energy,axis=0)\n",
    "        train_z = np.concatenate(train_z,axis=0)\n",
    "        train_labels = np.concatenate(train_labels,axis=0)\n",
    "\n",
    "\n",
    "        self.data_loader.dataset.mode=\"test\"\n",
    "        test_energy = []\n",
    "        test_labels = []\n",
    "        test_z = []\n",
    "        for it, (input_data, labels) in enumerate(self.data_loader):\n",
    "            input_data = self.to_var(input_data)\n",
    "            enc, dec, z, gamma = self.dagmm(input_data)\n",
    "            sample_energy, cov_diag = self.dagmm.compute_energy(z, size_average=False)\n",
    "            test_energy.append(sample_energy.data.cpu().numpy())\n",
    "            test_z.append(z.data.cpu().numpy())\n",
    "            test_labels.append(labels.numpy())\n",
    "\n",
    "\n",
    "        test_energy = np.concatenate(test_energy,axis=0)\n",
    "        test_z = np.concatenate(test_z,axis=0)\n",
    "        test_labels = np.concatenate(test_labels,axis=0)\n",
    "\n",
    "        combined_energy = np.concatenate([train_energy, test_energy], axis=0)\n",
    "        combined_labels = np.concatenate([train_labels, test_labels], axis=0)\n",
    "\n",
    "        thresh = np.percentile(combined_energy, 100 - 20)\n",
    "        print(\"Threshold :\", thresh)\n",
    "\n",
    "        pred = (test_energy > thresh).astype(int)\n",
    "        gt = test_labels.astype(int)\n",
    "\n",
    "        from sklearn.metrics import precision_recall_fscore_support as prf, accuracy_score\n",
    "\n",
    "        accuracy = accuracy_score(gt,pred)\n",
    "        precision, recall, f_score, support = prf(gt, pred, average='binary')\n",
    "\n",
    "        print(\"Accuracy : {:0.4f}, Precision : {:0.4f}, Recall : {:0.4f}, F-score : {:0.4f}\".format(accuracy, precision, recall, f_score))\n",
    "        \n",
    "        return accuracy, precision, recall, f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted KDDCup99 DAGMM.ipynb.\n",
      "Converted dagmm_data_loader.ipynb.\n",
      "Converted dagmm_main.ipynb.\n",
      "Converted dagmm_model.ipynb.\n",
      "Converted dagmm_solver.ipynb.\n",
      "Converted dagmm_utils.ipynb.\n",
      "Converted notebook_core.ipynb.\n",
      "Converted notebook_export.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "notebook2script(all_fs=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
