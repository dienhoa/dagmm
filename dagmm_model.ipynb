{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "import itertools\n",
    "from local.dagmm.utils import *\n",
    "from local.notebook.export import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp dagmm.model\n",
    "# default_cls_lvl 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Cholesky(torch.autograd.Function):\n",
    "    def forward(ctx, a):\n",
    "        l = torch.cholesky(a, False)\n",
    "        ctx.save_for_backward(l)\n",
    "        return l\n",
    "    def backward(ctx, grad_output):\n",
    "        l, = ctx.saved_variables\n",
    "        linv = l.inverse()\n",
    "        inner = torch.tril(torch.mm(l.t(), grad_output)) * torch.tril(\n",
    "            1.0 - Variable(l.data.new(l.size(1)).fill_(0.5).diag()))\n",
    "        s = torch.mm(linv.t(), torch.mm(inner, linv))\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class DaGMM(nn.Module):\n",
    "    \"\"\"Residual Block.\"\"\"\n",
    "    def __init__(self, n_gmm = 2, latent_dim=3):\n",
    "        super(DaGMM, self).__init__()\n",
    "\n",
    "        layers = []\n",
    "        layers += [nn.Linear(118,60)]\n",
    "        layers += [nn.Tanh()]        \n",
    "        layers += [nn.Linear(60,30)]\n",
    "        layers += [nn.Tanh()]        \n",
    "        layers += [nn.Linear(30,10)]\n",
    "        layers += [nn.Tanh()]        \n",
    "        layers += [nn.Linear(10,1)]\n",
    "\n",
    "        self.encoder = nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "        layers = []\n",
    "        layers += [nn.Linear(1,10)]\n",
    "        layers += [nn.Tanh()]        \n",
    "        layers += [nn.Linear(10,30)]\n",
    "        layers += [nn.Tanh()]        \n",
    "        layers += [nn.Linear(30,60)]\n",
    "        layers += [nn.Tanh()]        \n",
    "        layers += [nn.Linear(60,118)]\n",
    "\n",
    "        self.decoder = nn.Sequential(*layers)\n",
    "\n",
    "        layers = []\n",
    "        layers += [nn.Linear(latent_dim,10)]\n",
    "        layers += [nn.Tanh()]        \n",
    "        layers += [nn.Dropout(p=0.5)]        \n",
    "        layers += [nn.Linear(10,n_gmm)]\n",
    "        layers += [nn.Softmax(dim=1)]\n",
    "\n",
    "\n",
    "        self.estimation = nn.Sequential(*layers)\n",
    "\n",
    "        self.register_buffer(\"phi\", torch.zeros(n_gmm))\n",
    "        self.register_buffer(\"mu\", torch.zeros(n_gmm,latent_dim))\n",
    "        self.register_buffer(\"cov\", torch.zeros(n_gmm,latent_dim,latent_dim))\n",
    "\n",
    "    def relative_euclidean_distance(self, a, b):\n",
    "        return (a-b).norm(2, dim=1) / a.norm(2, dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        enc = self.encoder(x)\n",
    "\n",
    "        dec = self.decoder(enc)\n",
    "\n",
    "        rec_cosine = F.cosine_similarity(x, dec, dim=1)\n",
    "        rec_euclidean = self.relative_euclidean_distance(x, dec)\n",
    "\n",
    "        z = torch.cat([enc, rec_euclidean.unsqueeze(-1), rec_cosine.unsqueeze(-1)], dim=1)\n",
    "\n",
    "        gamma = self.estimation(z)\n",
    "\n",
    "        return enc, dec, z, gamma\n",
    "\n",
    "    def compute_gmm_params(self, z, gamma):\n",
    "        N = gamma.size(0)\n",
    "        # K\n",
    "        sum_gamma = torch.sum(gamma, dim=0)\n",
    "\n",
    "        # K\n",
    "        phi = (sum_gamma / N)\n",
    "\n",
    "        self.phi = phi.data\n",
    "\n",
    " \n",
    "        # K x D\n",
    "        mu = torch.sum(gamma.unsqueeze(-1) * z.unsqueeze(1), dim=0) / sum_gamma.unsqueeze(-1)\n",
    "        self.mu = mu.data\n",
    "        # z = N x D\n",
    "        # mu = K x D\n",
    "        # gamma N x K\n",
    "\n",
    "        # z_mu = N x K x D\n",
    "        z_mu = (z.unsqueeze(1)- mu.unsqueeze(0))\n",
    "\n",
    "        # z_mu_outer = N x K x D x D\n",
    "        z_mu_outer = z_mu.unsqueeze(-1) * z_mu.unsqueeze(-2)\n",
    "\n",
    "        # K x D x D\n",
    "        cov = torch.sum(gamma.unsqueeze(-1).unsqueeze(-1) * z_mu_outer, dim = 0) / sum_gamma.unsqueeze(-1).unsqueeze(-1)\n",
    "        self.cov = cov.data\n",
    "\n",
    "        return phi, mu, cov\n",
    "        \n",
    "    def compute_energy(self, z, phi=None, mu=None, cov=None, size_average=True):\n",
    "        if phi is None:\n",
    "            phi = self.phi.cuda()\n",
    "        if mu is None:\n",
    "            mu = self.mu.cuda()\n",
    "        if cov is None:\n",
    "            cov = self.cov.cuda()\n",
    "\n",
    "        k, D, _ = cov.size()\n",
    "\n",
    "        z_mu = (z.unsqueeze(1)- mu.unsqueeze(0))\n",
    "\n",
    "        cov_inverse = []\n",
    "        det_cov = []\n",
    "        cov_diag = 0\n",
    "        eps = 1e-12\n",
    "        for i in range(k):\n",
    "            # K x D x D\n",
    "            cov_k = cov[i] + (torch.eye(D)*eps).cuda()\n",
    "            cov_inverse.append(torch.inverse(cov_k).unsqueeze(0))\n",
    "\n",
    "            #det_cov.append(np.linalg.det(cov_k.data.cpu().numpy()* (2*np.pi)))\n",
    "            det_cov.append((Cholesky.apply(cov_k.cpu() * (2*np.pi)).diag().prod()).unsqueeze(0))\n",
    "            cov_diag = cov_diag + torch.sum(1 / cov_k.diag())\n",
    "\n",
    "        # K x D x D\n",
    "        cov_inverse = torch.cat(cov_inverse, dim=0)\n",
    "        # K\n",
    "        det_cov = torch.cat(det_cov).cuda()\n",
    "        #det_cov = to_var(torch.from_numpy(np.float32(np.array(det_cov))))\n",
    "\n",
    "        # N x K\n",
    "        exp_term_tmp = -0.5 * torch.sum(torch.sum(z_mu.unsqueeze(-1) * cov_inverse.unsqueeze(0), dim=-2) * z_mu, dim=-1)\n",
    "        # for stability (logsumexp)\n",
    "        max_val = torch.max((exp_term_tmp).clamp(min=0), dim=1, keepdim=True)[0]\n",
    "\n",
    "        exp_term = torch.exp(exp_term_tmp - max_val)\n",
    "\n",
    "        # sample_energy = -max_val.squeeze() - torch.log(torch.sum(phi.unsqueeze(0) * exp_term / (det_cov).unsqueeze(0), dim = 1) + eps)\n",
    "        sample_energy = -max_val.squeeze() - torch.log(torch.sum(phi.unsqueeze(0) * exp_term / (torch.sqrt(det_cov)).unsqueeze(0), dim = 1) + eps)\n",
    "        # sample_energy = -max_val.squeeze() - torch.log(torch.sum(phi.unsqueeze(0) * exp_term / (torch.sqrt((2*np.pi)**D * det_cov)).unsqueeze(0), dim = 1) + eps)\n",
    "\n",
    "\n",
    "        if size_average:\n",
    "            sample_energy = torch.mean(sample_energy)\n",
    "\n",
    "        return sample_energy, cov_diag\n",
    "\n",
    "\n",
    "    def loss_function(self, x, x_hat, z, gamma, lambda_energy, lambda_cov_diag):\n",
    "\n",
    "        recon_error = torch.mean((x - x_hat) ** 2)\n",
    "\n",
    "        phi, mu, cov = self.compute_gmm_params(z, gamma)\n",
    "\n",
    "        sample_energy, cov_diag = self.compute_energy(z, phi, mu, cov)\n",
    "\n",
    "        loss = recon_error + lambda_energy * sample_energy + lambda_cov_diag * cov_diag\n",
    "\n",
    "        return loss, sample_energy, recon_error, cov_diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted KDDCup99 DAGMM.ipynb.\n",
      "Converted dagmm_data_loader.ipynb.\n",
      "Converted dagmm_main.ipynb.\n",
      "Converted dagmm_model.ipynb.\n",
      "Converted dagmm_solver.ipynb.\n",
      "Converted dagmm_utils.ipynb.\n",
      "Converted notebook_core.ipynb.\n",
      "Converted notebook_export.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "notebook2script(all_fs=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
